{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dfa96a-eec0-4bc3-80c1-6c847aa283ce",
   "metadata": {},
   "source": [
    "# CMIP Future Realizations: Drought Targets, SPEI, and SPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f21d1-6c17-48a3-929d-26289936a380",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to determine the probabilities, calculated from 2031-2060 CMIP fitted log logistic distributions, for drought target, 3-month cumulative deficit values.\n",
    "\n",
    "SPEI and SPI, calculated using 2031-2060 CMIP, is also plotted for the future realizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48568e0-e423-4369-bc72-c22e3936232b",
   "metadata": {},
   "source": [
    "## Parameters and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24670d3b-b680-4104-b56d-3ba77a52b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f56a7e-905f-45fb-a216-12cd060e68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sstats\n",
    "from math import exp\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26db234-60b5-4c0e-a63b-7d1de40d1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a39a04-baf2-4f08-8de8-2fca23a264a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIR1 = r'C:\\Users\\nmartin\\Documents\\EAA_HCP\\Data\\SwRI_Processed\\Processed_Historical'\n",
    "IN_DIR2 = r'C:\\Users\\nmartin\\Documents\\EAA_HCP\\Data\\SwRI_Processed\\DayMet_GridIntersect'\n",
    "IN_DIR3 = r'C:\\Users\\nmartin\\Documents\\EAA_HCP\\Data\\SwRI_Processed\\CMIP6'\n",
    "IN_DIR4 = r'C:\\Users\\nmartin\\Documents\\EAA_HCP\\Data\\SwRI_Processed\\CMIP5'\n",
    "OUT_DIR = r'C:\\Users\\nmartin\\Documents\\EAA_HCP\\Data\\SwRI_Processed\\CombinedFuture\\Drought_Targets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472d1dc3-f80b-403e-99d5-f9a86be805aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our standard normal or ZScore parameters\n",
    "ZMu = 0.0\n",
    "ZStd = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5746b7a0-368f-4680-ab55-ae86f1edf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full basin intersection dictionary\n",
    "InFiler = os.path.normpath( os.path.join( IN_DIR2, \"BasWeightsGDF.pkl\" ) )\n",
    "with open( InFiler, 'rb' ) as IF:\n",
    "    BasWeightsDF = pickle.load( IF )\n",
    "# end with\n",
    "BAS_KEYS = sorted( BasWeightsDF.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4497a27a-bb61-4ea7-8bef-ae3de2ccfb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonDict = { 1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\", 7 : \"Jul\", 8 : \"Aug\",\n",
    "            9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\", }\n",
    "MonKeys = sorted( MonDict.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877bdcae-3c64-4abb-bd5f-e448007dc5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DICT = { 2 : [\"CMIP6\", [\"ssp245\", \"ssp585\"], ], \n",
    "               3 : [\"CMIP6\", [\"ssp245\", \"ssp585\"], ], \n",
    "               4 : [\"CMIP6\", [\"ssp245\", \"ssp585\"], ], \n",
    "               5 : [\"CMIP6\", [\"ssp245\", \"ssp585\"], ], \n",
    "               11 : [\"CMIP6\", [\"ssp245\", \"ssp585\"], ], \n",
    "               12 : [\"CMIP6\", [\"ssp245\", \"ssp585\"], ], \n",
    "               7 : [\"CMIP5\", [\"rcp45\", \"rcp85\"], ], \n",
    "               8 : [\"CMIP5\", [\"rcp45\", \"rcp85\"], ], \n",
    "               9 : [\"CMIP5\", [\"rcp45\", \"rcp85\"], ], \n",
    "               10 : [\"CMIP5\", [\"rcp85\"], ], }\n",
    "MODEL_KEYS = list( MODEL_DICT.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161ab7e7-8d39-4ca8-99f0-519deab34b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonIndexer = [ x for x in range(1,13,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "965bbcc7-3ebd-4058-9dcd-563f253e9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "PTSStart = pd.Timestamp( 1993, 1, 1, 0 )\n",
    "PTSStop = pd.Timestamp( 2022, 12, 31, 23, 59, )\n",
    "CNTSStart = pd.Timestamp( 2031, 1, 1, 0 )\n",
    "CNTSStop = pd.Timestamp( 2060, 12, 31, 23, 59, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec8dc0e-d7da-47c3-b790-2e0a74827ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProjModelOutsName = \"Mod_%02d_%s_2023through2080_%s_DF.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb37ab0-a5ad-428d-9bb9-3dab3fa7e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambdas\n",
    "setYrMo = lambda yr, mo: ( int(yr) * 100 ) + int(mo)\n",
    "calcYr = lambda indx: int( indx / 100 )\n",
    "calcMo = lambda indx, yr: int( indx - ( yr * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4335a22-b7d4-4776-a27b-2f3fa275d19c",
   "metadata": {},
   "source": [
    "**start skip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eefdac5a-4d4e-4d18-9e25-1fc002db6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InFiler = os.path.normpath( os.path.join( IN_DIR1, \"FBas_MetTS_1980through2020_Dict.pkl\" ) )\n",
    "#with open( InFiler, 'rb' ) as IF:\n",
    "#    OrgBasinsDFDict = pickle.load( IF )\n",
    "## end with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c039a8b-183c-46a0-b2a6-d4aa3aba6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InFiler = os.path.normpath( os.path.join( IN_DIR1, \"FBas_MetTS_2021through2022_Dict.pkl\" ) )\n",
    "#with open( InFiler, 'rb' ) as IF:\n",
    "#    ExBasinsDFDict = pickle.load( IF )\n",
    "## end with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5d7ce-fa82-4399-b1dd-d1bebc21b6c5",
   "metadata": {},
   "source": [
    "Combine the observed into single DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d386418d-9878-4410-87ae-b025e6c5c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BasinsDFDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f16cbd-88fb-490e-a733-78c3aad4711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for bas in BAS_KEYS:\n",
    "#    medDF = OrgBasinsDFDict[bas]\n",
    "#    newMedDF = ExBasinsDFDict[bas]\n",
    "#    fullMedDF = pd.concat( [ medDF, newMedDF ], )\n",
    "#    BasinsDFDict[bas] = fullMedDF.copy()\n",
    "## end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c35d2e3-6c54-4562-9c03-76292da26fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for future\n",
    "#OutFiler = os.path.normpath( os.path.join( IN_DIR1, \"FBas_MetTS_1980through2022_Dict.pkl\" ) )\n",
    "#with open( OutFiler, 'wb' ) as OF:\n",
    "#    pickle.dump( BasinsDFDict, OF, protocol=pickle.HIGHEST_PROTOCOL )\n",
    "## end with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92a1ff-518e-47f5-a4ee-42337790aab3",
   "metadata": {},
   "source": [
    "**end skip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "700374c2-d25a-4775-a31f-4be4d3d336f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full time series\n",
    "InFiler = os.path.normpath( os.path.join( IN_DIR1, \"FBas_MetTS_1980through2022_Dict.pkl\" ) )\n",
    "with open( InFiler, 'rb' ) as IF:\n",
    "    BasinsDFDict = pickle.load( IF )\n",
    "# end with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1675e55e-d7dd-4081-a26e-25e76e494790",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7700ff9f-5ac0-408d-af85-34c81376de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimatellogparams( npArray ):\n",
    "    \"\"\"Estimate the parameters of a log-logistic distribution from an\n",
    "    array of annual values.\n",
    "    \n",
    "    Estimate is done using L-moments and the \"Generalized logistic distribution\".\n",
    "    This distribtion is a reparameterized version of the log-logistic\n",
    "    distribution of Ahmad et al. (1988). Estimation is done using \n",
    "    the equations and procedure in Appendix A.7 of \"Regional Frequency\n",
    "    Analysis\", Hosking and Wallis (1997)\n",
    "    \n",
    "    To estimate the distribution parameters (shape, scale, and location),\n",
    "    the L-moments l1, l2, and t3 need to be calculated. These three\n",
    "    L-moments can be estimated from the first three, sample weighted\n",
    "    probability moments (b0, b1, and b2).\n",
    "    \n",
    "    Args:\n",
    "        npArray (np.ndarray): Numpy, 1D array\n",
    "    \n",
    "    Returns:\n",
    "        log-logistic parameters in dictionary, D:\n",
    "            D[\"k\"]: k or shape\n",
    "            D[\"scale\"]: alpha or scale\n",
    "            D[\"loc\"]: Eta or location\n",
    "    \"\"\"\n",
    "    # imports\n",
    "    import math\n",
    "    # don't do any checking for type and assume that will always\n",
    "    #  be Numpy ndarray for single argument\n",
    "    totLen = len( npArray )\n",
    "    # need a sorted array in increasing order\n",
    "    srtAr = np.sort( npArray )\n",
    "    # calculate sample probability weighted moments: b0, b1, b2\n",
    "    b0 = srtAr.mean()\n",
    "    b1 = 0.0\n",
    "    for iI in range(2, totLen + 1):\n",
    "        b1 += ( ( iI - 1 ) / ( totLen - 1 ) ) * srtAr[iI-1]\n",
    "    # end for\n",
    "    b1 = b1 / totLen\n",
    "    b2 = 0.0\n",
    "    for iI in range( 3, totLen + 1 ):\n",
    "        b2 += ( ( ( iI - 1 ) * ( iI - 2 ) ) / ( ( totLen - 1 ) * (totLen - 2 ) ) ) * srtAr[iI-1]\n",
    "    # end for\n",
    "    b2 = b2 / totLen\n",
    "    # calculate sample L-moments: l1, l2, t3\n",
    "    l1 = b0\n",
    "    l2 = (2.0 * b1 ) - b0\n",
    "    l3 = ( 6.0 * b2 ) -  ( 6.0 * b1 ) + b0\n",
    "    t3 = l3 / l2\n",
    "    # estimate the distribution parameters\n",
    "    shape = -1.0 * t3\n",
    "    scale = ( l2 * math.sin( shape * math.pi ) ) / ( shape * math.pi )\n",
    "    location = l1 - ( scale * ( ( 1.0 / shape ) - ( math.pi / math.sin( shape * math.pi ) ) ) )\n",
    "    retDict = { \"k\" : shape,\n",
    "                \"scale\" : scale,\n",
    "                \"loc\" : location, }\n",
    "    # return\n",
    "    return retDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2c657f-2ea0-420d-85d8-7b60f1945b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probDistLLogis( paramDict, npArray ):\n",
    "    \"\"\"Uses generalized logistic probability distribution to estimate cumulative\n",
    "    probilities for each value in the Numpy array, npArray.\n",
    "    \n",
    "    Args:\n",
    "        paramDict (dict): dictionary with best-fit parameter values for a \n",
    "                log-logisitic distribution. Must have keys: \"k\", \"scale\",\n",
    "                \"loc\" which are the 3 required parameters\n",
    "        npArray (np.ndarray): array from time series of monthly, rolling\n",
    "                average values\n",
    "    \n",
    "    Returns:\n",
    "        retArray (np.ndarray): cumulative probabilies for each npArray value\n",
    "    \"\"\"\n",
    "    shape = paramDict[\"k\"]\n",
    "    location = paramDict[\"loc\"]\n",
    "    scale = paramDict[\"scale\"]\n",
    "    if shape == 0.0:\n",
    "        # this is the special case of a logistic distribution with 2 params\n",
    "        y = ( npArray - location ) / scale\n",
    "    else:\n",
    "        # this is the general case of the log-logistic distribution\n",
    "        takeLogArray = 1.0 - ( shape * ( npArray - location ) / scale )\n",
    "        useLogArray = np.where( takeLogArray <= 0.0, 1e-7, takeLogArray )\n",
    "        y = ( -1.0 * ( 1.0 / shape ) ) * np.log( useLogArray )\n",
    "    # end if\n",
    "    retArray = 1.0 / ( 1.0 + np.exp( -1.0 * y  ) )\n",
    "    # return\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272372ea-5e83-492c-85b9-9de6702fb9e9",
   "metadata": {},
   "source": [
    "## Load the Drought Targets for Each Basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a2a60d4-c022-457e-b2bb-3026350b2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "DroughtTargsDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47dd8d95-ae82-4532-b256-e6946eaf0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bas in BAS_KEYS:\n",
    "    InFiler = os.path.normpath( os.path.join( IN_DIR1, \"SPEI\", bas, \"%s_drought_targets.xlsx\" % bas ) )\n",
    "    curDF = pd.read_excel( InFiler, sheet_name=\"Targets\", header=0, index_col=0, )\n",
    "    cumDefTarg = float( curDF.at[7, \"2022 Cum Def\"] )\n",
    "    cumProbOrig = float( curDF.at[7, \"2022 Cum Prob\"] )\n",
    "    DroughtTargsDict[bas] = [ 7, cumProbOrig, cumDefTarg, dict() ]\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccadd6-31e4-436f-98bd-67277f3e257b",
   "metadata": {},
   "source": [
    "## Get the Observed, Cumulative Deficits and Precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e8a2e67-4ee9-420d-a0ee-fcd3c441ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsCumDef = dict()\n",
    "ObsCumPre = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a89b5dd1-1cd0-4e20-908a-51901fde6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bas in BAS_KEYS:\n",
    "    curDF = BasinsDFDict[bas]\n",
    "    MonDF = curDF.resample( 'MS', ).sum()\n",
    "    PreMonDF = MonDF[[\"Pre_mm\"]].copy()\n",
    "    DefMonDF = MonDF[[\"Def_mm\"]].copy()\n",
    "    P3DF = PreMonDF.rolling(window=3,).sum()\n",
    "    D3DF = DefMonDF.rolling(window=3,).sum()\n",
    "    P3DF[\"Month\"] = P3DF.index.month\n",
    "    D3DF[\"Month\"] = D3DF.index.month\n",
    "    exP3DF = P3DF.loc[PTSStart:PTSStop].copy()\n",
    "    exD3DF = D3DF.loc[PTSStart:PTSStop].copy()\n",
    "    m3Mon = exP3DF[exP3DF[\"Month\"] == 1].copy()\n",
    "    a3Mon = m3Mon[\"Pre_mm\"].to_numpy(dtype=np.float32)\n",
    "    ObsCumPre[bas] = { 1 : a3Mon, }\n",
    "    m3Mon = exD3DF[exD3DF[\"Month\"] == 1].copy()\n",
    "    a3Mon = m3Mon[\"Def_mm\"].to_numpy(dtype=np.float32)\n",
    "    ObsCumDef[bas] = { 1 : a3Mon, }\n",
    "    for mon in range(2,13):\n",
    "        m3Mon = exP3DF[exP3DF[\"Month\"] == mon].copy()\n",
    "        a3Mon = m3Mon[\"Pre_mm\"].to_numpy(dtype=np.float32)\n",
    "        ObsCumPre[bas][mon] = a3Mon\n",
    "        m3Mon = exD3DF[exD3DF[\"Month\"] == mon].copy()\n",
    "        a3Mon = m3Mon[\"Def_mm\"].to_numpy(dtype=np.float32)\n",
    "        ObsCumDef[bas][mon] = a3Mon\n",
    "    # end month for\n",
    "# end basin for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ba581-3c57-416c-a465-cc983de9aa21",
   "metadata": {},
   "source": [
    "## SPEI and SPI with Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac85fbd-1ee4-4526-9e3c-2b1ebb788f46",
   "metadata": {},
   "source": [
    "Do the SPEI calculation for each basin and model and scenario pair. Calculate the SPEI for 2031 through 2060."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f225c59c-59fa-4686-990e-5f911d048d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMax = 3.0\n",
    "pMin = -3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e31febd-c190-4130-bfa7-d65ec243180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cColors = [ \"darkred\", \"firebrick\", \"indianred\", \"lightcoral\", \"lightsalmon\", \"antiquewhite\",\n",
    "            \"antiquewhite\", \"antiquewhite\", \"lightblue\", \"cadetblue\", \"royalblue\", \"mediumblue\", \"midnightblue\" ]\n",
    "# -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0\n",
    "cNodes = [0.0, 0.0833, 0.1666, 0.25, 0.3333, 0.4166, 0.50, 0.5833, 0.666, 0.75, 0.8333, 0.9166, 1.0 ]\n",
    "len(cColors), len(cNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66f7bc26-92bd-4190-a078-b4d0917f03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SegCMap = mpl.colors.LinearSegmentedColormap.from_list(\"spei_cmap\", list(zip(cNodes, cColors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39a53498-c5ca-45ef-9506-5936411a6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "BasinArrayPreDict = dict()\n",
    "BasinArrayDefDict = dict()\n",
    "for bas in BAS_KEYS:\n",
    "    BasinArrayPreDict[bas] = dict()\n",
    "    BasinArrayDefDict[bas] = dict()\n",
    "    for mon in MonIndexer:\n",
    "        BasinArrayPreDict[bas][mon] = list()\n",
    "        BasinArrayDefDict[bas][mon] = list()\n",
    "    # end for\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1230bba2-17b6-44a2-8437-6d4b3d1261a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bas in BAS_KEYS:\n",
    "    # do all models\n",
    "    mDictDF = dict()\n",
    "    mStatsDictDF = dict()\n",
    "    for mKey in MODEL_KEYS:\n",
    "        mVals = MODEL_DICT[mKey]\n",
    "        cMiper = mVals[0]\n",
    "        curSens = mVals[1]\n",
    "        if cMiper == \"CMIP6\":\n",
    "            inDir = IN_DIR3\n",
    "        else:\n",
    "            inDir = IN_DIR4\n",
    "        # end if\n",
    "        for tSen in curSens:\n",
    "            if tSen in [\"ssp585\", \"rcp85\"]:\n",
    "                mLabeler = \"M%02dH 2031-2060\" % mKey\n",
    "            else:\n",
    "                mLabeler = \"M%02dL 2031-2060\" % mKey\n",
    "            # end if\n",
    "            InFiler = os.path.normpath( os.path.join( inDir, ProjModelOutsName % (mKey, tSen, bas) ) )\n",
    "            cModDDF = pd.read_pickle( InFiler )\n",
    "            cModDDF[\"YrMo\"] = cModDDF.apply( lambda row: setYrMo( row[\"Year\"], row[\"Month\"] ), axis=1 )\n",
    "            cModDDF = cModDDF[(cModDDF[\"Year\"] >= 2030) & (cModDDF[\"Year\"] <= 2060)].copy()\n",
    "            cMMonPre = cModDDF[[\"Pre_mm\", \"YrMo\"]].groupby(by=\"YrMo\").sum()\n",
    "            cMMonDef = cModDDF[[\"Def_mm\", \"YrMo\"]].groupby(by=\"YrMo\").sum()\n",
    "            cMMonPre[\"PreCS\"] = cMMonPre[\"Pre_mm\"].rolling(window=3,).sum()\n",
    "            cMMonDef[\"DefCS\"] = cMMonDef[\"Def_mm\"].rolling(window=3,).sum()\n",
    "            cMMonPre[\"Year\"] = [ int( x / 100 ) for x in cMMonPre.index.to_list() ]\n",
    "            cMMonDef[\"Year\"] = [ int( x / 100 ) for x in cMMonDef.index.to_list() ]\n",
    "            cMMonPre[\"Month\"] = [ int( x - ( y * 100 ) ) for x,y in zip( cMMonPre.index.to_list(), cMMonPre[\"Year\"].to_list() ) ]\n",
    "            cMMonDef[\"Month\"] = [ int( x - ( y * 100 ) ) for x,y in zip( cMMonDef.index.to_list(), cMMonDef[\"Year\"].to_list() ) ]\n",
    "            cMMonPre = cMMonPre[(cMMonPre[\"Year\"] >= 2031) & (cMMonPre[\"Year\"] <= 2060)].copy()\n",
    "            cMMonDef = cMMonDef[(cMMonDef[\"Year\"] >= 2031) & (cMMonDef[\"Year\"] <= 2060)].copy()\n",
    "            # go through each month\n",
    "            PreM3MonDict = dict()\n",
    "            DefM3MonDict = dict()\n",
    "            for mon in MonIndexer:\n",
    "                # SPI\n",
    "                m3Mon = cMMonPre[cMMonPre[\"Month\"] == mon].copy()\n",
    "                a3Mon = m3Mon[\"PreCS\"].to_numpy(dtype=np.float32)\n",
    "                BasinArrayPreDict[bas][mon].append( a3Mon )\n",
    "                extA3Mon = deepcopy( ObsCumPre[bas][mon] )\n",
    "                fitT3Mon = sstats.pearson3.fit( a3Mon )\n",
    "                lD3Mon = { \"skew\" : fitT3Mon[0], \"location\" : fitT3Mon[1],\n",
    "                           \"scale\" : fitT3Mon[2], }\n",
    "                # now get the cumulative probability values from the distributions\n",
    "                #   for the observed values.\n",
    "                pre3MCDF = sstats.pearson3.cdf( a3Mon, lD3Mon[\"skew\"], loc=lD3Mon[\"location\"], \n",
    "                                                scale=lD3Mon[\"scale\"] )\n",
    "                hpre3MCDF = sstats.pearson3.cdf( extA3Mon, lD3Mon[\"skew\"], loc=lD3Mon[\"location\"], \n",
    "                                                 scale=lD3Mon[\"scale\"] )\n",
    "                # make sure the cumulative density is not less than 1.0 / (2* N years).\n",
    "                pre3MCDF = np.where( pre3MCDF < (1.0/60.0), (1.0/60.0), pre3MCDF )\n",
    "                hpre3MCDF = np.where( hpre3MCDF < (1.0/60.0), (1.0/60.0), hpre3MCDF )\n",
    "                SPI3Mo = sstats.norm.ppf( pre3MCDF, loc=ZMu, scale=ZStd )\n",
    "                hSPI3Mo = sstats.norm.ppf( hpre3MCDF, loc=ZMu, scale=ZStd )\n",
    "                # dictionary entries for this month\n",
    "                PreM3MonDict[mon] = [ [pre3MCDF, hpre3MCDF, SPI3Mo, hSPI3Mo, a3Mon, extA3Mon], deepcopy( lD3Mon ) ]\n",
    "                # SPEI\n",
    "                m3Mon = cMMonDef[cMMonDef[\"Month\"] == mon].copy()\n",
    "                a3Mon = m3Mon[\"DefCS\"].to_numpy(dtype=np.float32)\n",
    "                BasinArrayDefDict[bas][mon].append( a3Mon )\n",
    "                extA3Mon = deepcopy( ObsCumDef[bas][mon] )\n",
    "                # fit 'generalized logistic' distributions to these arrays\n",
    "                lD3Mon = estimatellogparams( a3Mon )\n",
    "                # now get the cumulative probability values from the distributions\n",
    "                #   for the observed values.\n",
    "                hdef3MCDF = probDistLLogis( lD3Mon, extA3Mon )\n",
    "                def3MCDF = probDistLLogis( lD3Mon, a3Mon )\n",
    "                # make sure the cumulative density is not less than 1.0 / (2* N years).\n",
    "                hdef3MCDF = np.where( hdef3MCDF < (1.0/60.0), (1.0/60.0), hdef3MCDF )\n",
    "                def3MCDF = np.where( def3MCDF < (1.0/60.0), (1.0/60.0), def3MCDF )\n",
    "                SPEI3Mo = sstats.norm.ppf( def3MCDF, loc=ZMu, scale=ZStd )\n",
    "                hSPEI3Mo = sstats.norm.ppf( hdef3MCDF, loc=ZMu, scale=ZStd )\n",
    "                # dictionary entries for this month\n",
    "                DefM3MonDict[mon] = [ [def3MCDF, hdef3MCDF, SPEI3Mo, hSPEI3Mo, a3Mon, extA3Mon], deepcopy( lD3Mon ) ]\n",
    "                # if the month is July then calculate our drought target probability\n",
    "                if mon == 7:\n",
    "                    # get our probability for the target cumulative deficit\n",
    "                    curDTargProb = probDistLLogis( lD3Mon, np.array( [float(DroughtTargsDict[bas][2])], dtype=np.float32 ) )\n",
    "                    curDTargProb = np.where( curDTargProb < (1.0/60.0), (1.0/60.0), curDTargProb )\n",
    "                    # assign to drought targest dictionary\n",
    "                    DroughtTargsDict[bas][3][mLabeler] = float( curDTargProb[0] )\n",
    "                # end if\n",
    "            # end month for\n",
    "            # rebuild time series in calendar month format\n",
    "            # rebuild time series representation from calendar month lists\n",
    "            spi3mList = list()\n",
    "            Hspi3mList = list()\n",
    "            cpSPI3mList = list()\n",
    "            HcpSPI3mList = list()\n",
    "            cdSPI3mList = list()\n",
    "            HcdSPI3mList = list()\n",
    "            spei3mList = list()\n",
    "            Hspei3mList = list()\n",
    "            cpSPEI3mList = list()\n",
    "            HcpSPEI3mList = list()\n",
    "            cdSPEI3mList = list()\n",
    "            HcdSPEI3mList = list()\n",
    "            # loop through years and fill by month order\n",
    "            for yI in range(30):\n",
    "                for mI in range(1, 13, 1):\n",
    "                    m3SPIArrayCP = PreM3MonDict[mI][0][0]\n",
    "                    Hm3SPIArrayCP = PreM3MonDict[mI][0][1]\n",
    "                    m3SPIArraySP = PreM3MonDict[mI][0][2]\n",
    "                    Hm3SPIArraySP = PreM3MonDict[mI][0][3]\n",
    "                    m3SPIArrayCD = PreM3MonDict[mI][0][4]\n",
    "                    Hm3SPIArrayCD = PreM3MonDict[mI][0][5]\n",
    "                    m3SPEIArrayCP = DefM3MonDict[mI][0][0]\n",
    "                    Hm3SPEIArrayCP = DefM3MonDict[mI][0][1]\n",
    "                    m3SPEIArraySP = DefM3MonDict[mI][0][2]\n",
    "                    Hm3SPEIArraySP = DefM3MonDict[mI][0][3]\n",
    "                    m3SPEIArrayCD = DefM3MonDict[mI][0][4]\n",
    "                    Hm3SPEIArrayCD = DefM3MonDict[mI][0][5]\n",
    "                    if yI < len( m3SPIArrayCP ):\n",
    "                        spi3mList.append( m3SPIArraySP[yI] )\n",
    "                        Hspi3mList.append( Hm3SPIArraySP[yI] )\n",
    "                        cpSPI3mList.append( m3SPIArrayCP[yI] )\n",
    "                        HcpSPI3mList.append( Hm3SPIArrayCP[yI] )\n",
    "                        cdSPI3mList.append( m3SPIArrayCD[yI] )\n",
    "                        HcdSPI3mList.append( Hm3SPIArrayCD[yI] )\n",
    "                        spei3mList.append( m3SPEIArraySP[yI] )\n",
    "                        Hspei3mList.append( Hm3SPEIArraySP[yI] )\n",
    "                        cpSPEI3mList.append( m3SPEIArrayCP[yI] )\n",
    "                        HcpSPEI3mList.append( Hm3SPEIArrayCP[yI] )\n",
    "                        cdSPEI3mList.append( m3SPEIArrayCD[yI] )\n",
    "                        HcdSPEI3mList.append( m3SPEIArrayCD[yI] )\n",
    "                    # end if\n",
    "                # end inner for\n",
    "            # end outer for\n",
    "            # now build the time indexed DataFrame\n",
    "            DataDict = { \"Year\" : cMMonPre[\"Year\"].to_numpy(dtype=np.int32),\n",
    "                         \"Month\" : cMMonPre[\"Month\"].to_numpy(dtype=np.int32),\n",
    "                         \"CumPre\" : np.array( cdSPI3mList, dtype=np.float32 ),\n",
    "                         \"Hist_CumPre\" : np.array( HcdSPI3mList, dtype=np.float32 ),\n",
    "                         \"CumPreProb\" : np.array( cpSPI3mList, dtype=np.float32 ),\n",
    "                         \"Hist_CumPreProb\" : np.array( HcpSPI3mList, dtype=np.float32 ),\n",
    "                         \"SPI\" : np.array( spi3mList, dtype=np.float32 ),\n",
    "                         \"Hist_SPI\" : np.array( Hspi3mList, dtype=np.float32 ),\n",
    "                         \"CumDef\" : np.array( cdSPEI3mList, dtype=np.float32 ),\n",
    "                         \"Hist_CumDef\" : np.array( HcdSPEI3mList, dtype=np.float32 ),\n",
    "                         \"CumDefProb\" : np.array( cpSPEI3mList, dtype=np.float32 ), \n",
    "                         \"Hist_CumDefProb\" : np.array( HcpSPEI3mList, dtype=np.float32 ), \n",
    "                         \"SPEI\" : np.array( spei3mList, dtype=np.float32 ),\n",
    "                         \"Hist_SPEI\" : np.array( Hspei3mList, dtype=np.float32 ), }\n",
    "            cSP_3 = pd.DataFrame( index=cMMonPre.index, data=DataDict )\n",
    "            mDictDF[mLabeler] = cSP_3.copy()\n",
    "            # now do the stats\n",
    "            stats3SPIList = list()\n",
    "            stats3SPEIList = list()\n",
    "            indINList = list()\n",
    "            indENList = list()\n",
    "            for mI in range(1, 13, 1):\n",
    "                lDPre3Mon = PreM3MonDict[mI][1]\n",
    "                indINList.append( \"skew_%d\" % mI )\n",
    "                indINList.append( \"scale_%d\" % mI )\n",
    "                indINList.append( \"loc_%d\" % mI )\n",
    "                stats3SPIList.append( lDPre3Mon[\"skew\"] )\n",
    "                stats3SPIList.append( lDPre3Mon[\"scale\"] )\n",
    "                stats3SPIList.append( lDPre3Mon[\"location\"] )\n",
    "                lDDef3Mon = DefM3MonDict[mI][1]\n",
    "                indENList.append( \"shape_%d\" % mI )\n",
    "                indENList.append( \"scale_%d\" % mI )\n",
    "                indENList.append( \"loc_%d\" % mI )\n",
    "                stats3SPEIList.append( lDDef3Mon[\"k\"] )\n",
    "                stats3SPEIList.append( lDDef3Mon[\"scale\"] )\n",
    "                stats3SPEIList.append( lDDef3Mon[\"loc\"] )\n",
    "            # end for\n",
    "            # build our DataFrames\n",
    "            c3SPIStatsDF = pd.DataFrame( index=indINList, data={\"SPI Fit Stats\" : stats3SPIList,} )\n",
    "            c3SPEIStatsDF = pd.DataFrame( index=indENList, data={\"SPEI Fit Stats\" : stats3SPEIList,} )\n",
    "            mStatsDictDF[mLabeler] = [c3SPIStatsDF.copy(), c3SPEIStatsDF.copy()]\n",
    "            # do our plots\n",
    "            # SPEI\n",
    "            bT3Mo = cSP_3[[\"Year\", \"Month\", \"Hist_SPEI\"]].copy()\n",
    "            bT3Mo[\"AltYear\"] = bT3Mo[\"Year\"] - 38\n",
    "            pvbT3Mo = bT3Mo.pivot( index=\"AltYear\", columns=\"Month\", values=\"Hist_SPEI\")\n",
    "            NumYrs = len( pvbT3Mo )\n",
    "            allSPEI_1 = pvbT3Mo.to_numpy( dtype=np.float32 )\n",
    "            matLister1 = list()\n",
    "            for iI in range( NumYrs ):\n",
    "                rowLister = list()\n",
    "                for jJ in range(12):\n",
    "                    cVal = allSPEI_1[iI, jJ]\n",
    "                    if ( cVal >= 1.5 ) or ( cVal <= -1.5 ):\n",
    "                        rowLister.append( \"%4.1f\" % cVal )\n",
    "                    else:\n",
    "                        rowLister.append( \"\" )\n",
    "                    # end if\n",
    "                # end inner for\n",
    "                matLister1.append( rowLister )\n",
    "            # end outer for\n",
    "            AnnotMat_1 = np.array( matLister1 )\n",
    "            OutFilePDF = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"%s_%s_SPEI_3mon-1993to2022.pdf\" % (bas, mLabeler) ) )\n",
    "            OutFileSVG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"%s_%s_SPEI_3mon-1993to2022.svg\" % (bas, mLabeler) ) )\n",
    "            OutFilePNG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"%s_%s_SPEI_3mon-1993to2022.png\" % (bas, mLabeler) ) )\n",
    "            Fig1 = plt.figure()\n",
    "            Fig1.set_size_inches(7.5, 10.5)\n",
    "            ax11 = Fig1.add_subplot(111)\n",
    "            ax11 = sns.heatmap( pvbT3Mo, vmin=pMin, vmax=pMax, cmap=SegCMap, center=0.0,\n",
    "                                annot=AnnotMat_1, fmt=\"s\", linecolor=\"gainsboro\", linewidths=0.0,\n",
    "                                annot_kws={'fontsize':9, 'color':'xkcd:black'},\n",
    "                                cbar_kws={'label': 'SPEI',}, ax=ax11 )\n",
    "            cbar = ax11.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=9)\n",
    "            ax11.set_title( \"%s Basin – %s, 3-month SPEI (2031-2060 CN)\" % (bas, mLabeler), fontsize=12 )\n",
    "            ax11.set_xlabel('Month', fontsize=10 )\n",
    "            ax11.set_ylabel('Year', fontsize=10)\n",
    "            ax11.tick_params(axis='both', which='major', labelsize=10)\n",
    "            Fig1.savefig( OutFileSVG, dpi=600 )\n",
    "            Fig1.savefig( OutFilePNG, dpi=600 )\n",
    "            Fig1.savefig( OutFilePDF, dpi=600 )\n",
    "            # clear the figures\n",
    "            plt.cla()\n",
    "            plt.close(Fig1)\n",
    "            # SPI\n",
    "            bT3Mo = cSP_3[[\"Year\", \"Month\", \"Hist_SPI\"]].copy()\n",
    "            bT3Mo[\"AltYear\"] = bT3Mo[\"Year\"] - 38\n",
    "            pvbT3Mo = bT3Mo.pivot( index=\"AltYear\", columns=\"Month\", values=\"Hist_SPI\")\n",
    "            NumYrs = len( pvbT3Mo )\n",
    "            allSPEI_1 = pvbT3Mo.to_numpy( dtype=np.float32 )\n",
    "            matLister1 = list()\n",
    "            for iI in range( NumYrs ):\n",
    "                rowLister = list()\n",
    "                for jJ in range(12):\n",
    "                    cVal = allSPEI_1[iI, jJ]\n",
    "                    if ( cVal >= 1.5 ) or ( cVal <= -1.5 ):\n",
    "                        rowLister.append( \"%4.1f\" % cVal )\n",
    "                    else:\n",
    "                        rowLister.append( \"\" )\n",
    "                    # end if\n",
    "                # end inner for\n",
    "                matLister1.append( rowLister )\n",
    "            # end outer for\n",
    "            AnnotMat_1 = np.array( matLister1 )\n",
    "            OutFilePDF = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"%s_%s_SPI_3mon-1993to2022.pdf\" % (bas, mLabeler) ) )\n",
    "            OutFileSVG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"%s_%s_SPI_3mon-1993to2022.svg\" % (bas, mLabeler) ) )\n",
    "            OutFilePNG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"%s_%s_SPI_3mon-1993to2022.png\" % (bas, mLabeler) ) )\n",
    "            Fig1 = plt.figure()\n",
    "            Fig1.set_size_inches(7.5, 10.5)\n",
    "            ax11 = Fig1.add_subplot(111)\n",
    "            ax11 = sns.heatmap( pvbT3Mo, vmin=pMin, vmax=pMax, cmap=SegCMap, center=0.0,\n",
    "                                annot=AnnotMat_1, fmt=\"s\", linecolor=\"gainsboro\", linewidths=0.0,\n",
    "                                annot_kws={'fontsize':9, 'color':'xkcd:black'},\n",
    "                                cbar_kws={'label': 'SPI',}, ax=ax11 )\n",
    "            cbar = ax11.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=9)\n",
    "            ax11.set_title( \"%s Basin – %s, 3-month SPI (2031-2060 CN)\" % (bas, mLabeler), fontsize=12 )\n",
    "            ax11.set_xlabel('Month', fontsize=10 )\n",
    "            ax11.set_ylabel('Year', fontsize=10)\n",
    "            ax11.tick_params(axis='both', which='major', labelsize=10)\n",
    "            Fig1.savefig( OutFileSVG, dpi=600 )\n",
    "            Fig1.savefig( OutFilePNG, dpi=600 )\n",
    "            Fig1.savefig( OutFilePDF, dpi=600 )\n",
    "            # clear the figures\n",
    "            plt.cla()\n",
    "            plt.close(Fig1)\n",
    "        # end scenario for\n",
    "    # end model for\n",
    "    # output stuff that needs to be output for this basin\n",
    "    outXLSX = os.path.normpath( os.path.join( OUT_DIR, \"%s_SPEI_and_SPI.xlsx\" % bas ) )\n",
    "    writer = pd.ExcelWriter( outXLSX )\n",
    "    workbook  = writer.book\n",
    "    format1 = workbook.add_format({'num_format': '#,##0.00'})\n",
    "    allKeys = list( mDictDF.keys() )\n",
    "    for mLabel in allKeys:\n",
    "        cSPIStats = mStatsDictDF[mLabel][0]\n",
    "        cSPEIStats = mStatsDictDF[mLabel][1]\n",
    "        curDF = mDictDF[mLabel]\n",
    "        cLabel = \"%s_SPI_Info\" % mLabel\n",
    "        cSPIStats.to_excel( writer, sheet_name=cLabel, index_label=\"Parameter\" )\n",
    "        # adjust columns\n",
    "        writer.sheets[cLabel].set_column( 0, 0, 15 )\n",
    "        for column in cSPIStats:\n",
    "            column_width = max(cSPIStats[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "            col_idx = cSPIStats.columns.get_loc(column)\n",
    "            writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "        # end for\n",
    "        cLabel = \"%s_SPEI_Info\" % mLabel\n",
    "        cSPEIStats.to_excel( writer, sheet_name=cLabel, index_label=\"Parameter\" )\n",
    "        # adjust columns\n",
    "        writer.sheets[cLabel].set_column( 0, 0, 15 )\n",
    "        for column in cSPEIStats:\n",
    "            column_width = max(cSPEIStats[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "            col_idx = cSPEIStats.columns.get_loc(column)\n",
    "            writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "        # end for\n",
    "        cLabel = \"%s_Results\" % mLabel\n",
    "        curDF.to_excel( writer, sheet_name=cLabel, )\n",
    "        # adjust columns\n",
    "        writer.sheets[cLabel].set_column( 0, 0, 15 )\n",
    "        for column in curDF:\n",
    "            column_width = max(curDF[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "            col_idx = curDF.columns.get_loc(column)\n",
    "            writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "        # end for\n",
    "    # end model out for\n",
    "    writer.close()\n",
    "# end basin for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef63c0-c12d-4baa-8dcd-703deff5e4e4",
   "metadata": {},
   "source": [
    "## Do Ensemble Calcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5249101-cc3d-48e6-8d19-7ab19e5d19ee",
   "metadata": {},
   "source": [
    "The full basin calcs aggregate the individual model runs into an ensemble analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd818b70-5f96-4ad0-9648-ccb0a438f847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npList = BasinArrayPreDict[BAS_KEYS[0]][7]\n",
    "len(npList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd866a8d-70cf-4ebb-804c-959b2465a4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testA = np.concatenate( npList )\n",
    "testA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e40a87a9-8306-49ac-a162-7ee5a230088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DictDF = dict()\n",
    "StatsDictDF = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01f4eb0e-7f86-4de8-935d-65fee2cd4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bas in BAS_KEYS:\n",
    "    # only work on basins\n",
    "    PreM3MonDict = dict()\n",
    "    DefM3MonDict = dict()\n",
    "    for mon in MonIndexer:\n",
    "        cMonPreList = BasinArrayPreDict[bas][mon]\n",
    "        cMonPre = np.concatenate( cMonPreList )\n",
    "        cMonDefList = BasinArrayDefDict[bas][mon]\n",
    "        cMonDef = np.concatenate( cMonDefList )\n",
    "        # SPI\n",
    "        a3Mon = cMonPre\n",
    "        extA3Mon = deepcopy( ObsCumPre[bas][mon] )\n",
    "        fitT3Mon = sstats.pearson3.fit( a3Mon )\n",
    "        lD3Mon = { \"skew\" : fitT3Mon[0], \"location\" : fitT3Mon[1],\n",
    "                   \"scale\" : fitT3Mon[2], }\n",
    "        # now get the cumulative probability values from the distributions\n",
    "        #   for the observed values.\n",
    "        pre3MCDF = sstats.pearson3.cdf( a3Mon, lD3Mon[\"skew\"], loc=lD3Mon[\"location\"], \n",
    "                                        scale=lD3Mon[\"scale\"] )\n",
    "        hpre3MCDF = sstats.pearson3.cdf( extA3Mon, lD3Mon[\"skew\"], loc=lD3Mon[\"location\"], \n",
    "                                         scale=lD3Mon[\"scale\"] )\n",
    "        # make sure the cumulative density is not less than 1.0 / (2* N years).\n",
    "        pre3MCDF = np.where( pre3MCDF < (1.0/60.0), (1.0/60.0), pre3MCDF )\n",
    "        hpre3MCDF = np.where( hpre3MCDF < (1.0/60.0), (1.0/60.0), hpre3MCDF )\n",
    "        SPI3Mo = sstats.norm.ppf( pre3MCDF, loc=ZMu, scale=ZStd )\n",
    "        hSPI3Mo = sstats.norm.ppf( hpre3MCDF, loc=ZMu, scale=ZStd )\n",
    "        # dictionary entries for this month\n",
    "        PreM3MonDict[mon] = [ [pre3MCDF, hpre3MCDF, SPI3Mo, hSPI3Mo, a3Mon, extA3Mon], deepcopy( lD3Mon ) ]\n",
    "        # SPEI\n",
    "        a3Mon = cMonDef\n",
    "        extA3Mon = deepcopy( ObsCumDef[bas][mon] )\n",
    "        # fit 'generalized logistic' distributions to these arrays\n",
    "        lD3Mon = estimatellogparams( a3Mon )\n",
    "        # now get the cumulative probability values from the distributions\n",
    "        #   for the observed values.\n",
    "        hdef3MCDF = probDistLLogis( lD3Mon, extA3Mon )\n",
    "        def3MCDF = probDistLLogis( lD3Mon, a3Mon )\n",
    "        # make sure the cumulative density is not less than 1.0 / (2* N years).\n",
    "        hdef3MCDF = np.where( hdef3MCDF < (1.0/60.0), (1.0/60.0), hdef3MCDF )\n",
    "        def3MCDF = np.where( def3MCDF < (1.0/60.0), (1.0/60.0), def3MCDF )\n",
    "        SPEI3Mo = sstats.norm.ppf( def3MCDF, loc=ZMu, scale=ZStd )\n",
    "        hSPEI3Mo = sstats.norm.ppf( hdef3MCDF, loc=ZMu, scale=ZStd )\n",
    "        # dictionary entries for this month\n",
    "        DefM3MonDict[mon] = [ [def3MCDF, hdef3MCDF, SPEI3Mo, hSPEI3Mo, a3Mon, extA3Mon], deepcopy( lD3Mon ) ]\n",
    "        # if the month is July then calculate our drought target probability\n",
    "        if mon == 7:\n",
    "            # get our probability for the target cumulative deficit\n",
    "            curDTargProb = probDistLLogis( lD3Mon, np.array( [float(DroughtTargsDict[bas][2])], dtype=np.float32 ) )\n",
    "            curDTargProb = np.where( curDTargProb < (1.0/60.0), (1.0/60.0), curDTargProb )\n",
    "            # assign to drought targest dictionary\n",
    "            DroughtTargsDict[bas][3][\"ensemble\"] = float( curDTargProb[0] )\n",
    "        # end if\n",
    "    # end month for\n",
    "    # rebuild time series representation from calendar month lists\n",
    "    spi3mList = list()\n",
    "    Hspi3mList = list()\n",
    "    cpSPI3mList = list()\n",
    "    HcpSPI3mList = list()\n",
    "    cdSPI3mList = list()\n",
    "    HcdSPI3mList = list()\n",
    "    spei3mList = list()\n",
    "    Hspei3mList = list()\n",
    "    cpSPEI3mList = list()\n",
    "    HcpSPEI3mList = list()\n",
    "    cdSPEI3mList = list()\n",
    "    HcdSPEI3mList = list()\n",
    "    # loop through years and fill by month order\n",
    "    for yI in range(30):\n",
    "        for mI in range(1, 13, 1):\n",
    "            m3SPIArrayCP = PreM3MonDict[mI][0][0]\n",
    "            Hm3SPIArrayCP = PreM3MonDict[mI][0][1]\n",
    "            m3SPIArraySP = PreM3MonDict[mI][0][2]\n",
    "            Hm3SPIArraySP = PreM3MonDict[mI][0][3]\n",
    "            m3SPIArrayCD = PreM3MonDict[mI][0][4]\n",
    "            Hm3SPIArrayCD = PreM3MonDict[mI][0][5]\n",
    "            m3SPEIArrayCP = DefM3MonDict[mI][0][0]\n",
    "            Hm3SPEIArrayCP = DefM3MonDict[mI][0][1]\n",
    "            m3SPEIArraySP = DefM3MonDict[mI][0][2]\n",
    "            Hm3SPEIArraySP = DefM3MonDict[mI][0][3]\n",
    "            m3SPEIArrayCD = DefM3MonDict[mI][0][4]\n",
    "            Hm3SPEIArrayCD = DefM3MonDict[mI][0][5]\n",
    "            if yI < len( m3SPIArrayCP ):\n",
    "                spi3mList.append( m3SPIArraySP[yI] )\n",
    "                Hspi3mList.append( Hm3SPIArraySP[yI] )\n",
    "                cpSPI3mList.append( m3SPIArrayCP[yI] )\n",
    "                HcpSPI3mList.append( Hm3SPIArrayCP[yI] )\n",
    "                cdSPI3mList.append( m3SPIArrayCD[yI] )\n",
    "                HcdSPI3mList.append( Hm3SPIArrayCD[yI] )\n",
    "                spei3mList.append( m3SPEIArraySP[yI] )\n",
    "                Hspei3mList.append( Hm3SPEIArraySP[yI] )\n",
    "                cpSPEI3mList.append( m3SPEIArrayCP[yI] )\n",
    "                HcpSPEI3mList.append( Hm3SPEIArrayCP[yI] )\n",
    "                cdSPEI3mList.append( m3SPEIArrayCD[yI] )\n",
    "                HcdSPEI3mList.append( m3SPEIArrayCD[yI] )\n",
    "            # end if\n",
    "        # end inner for\n",
    "    # end outer for\n",
    "    # now build the time indexed DataFrame\n",
    "    DataDict = { \"Year\" : cMMonPre[\"Year\"].to_numpy(dtype=np.int32),\n",
    "                 \"Month\" : cMMonPre[\"Month\"].to_numpy(dtype=np.int32),\n",
    "                 \"CumPre\" : np.array( cdSPI3mList, dtype=np.float32 ),\n",
    "                 \"Hist_CumPre\" : np.array( HcdSPI3mList, dtype=np.float32 ),\n",
    "                 \"CumPreProb\" : np.array( cpSPI3mList, dtype=np.float32 ),\n",
    "                 \"Hist_CumPreProb\" : np.array( HcpSPI3mList, dtype=np.float32 ),\n",
    "                 \"SPI\" : np.array( spi3mList, dtype=np.float32 ),\n",
    "                 \"Hist_SPI\" : np.array( Hspi3mList, dtype=np.float32 ),\n",
    "                 \"CumDef\" : np.array( cdSPEI3mList, dtype=np.float32 ),\n",
    "                 \"Hist_CumDef\" : np.array( HcdSPEI3mList, dtype=np.float32 ),\n",
    "                 \"CumDefProb\" : np.array( cpSPEI3mList, dtype=np.float32 ), \n",
    "                 \"Hist_CumDefProb\" : np.array( HcpSPEI3mList, dtype=np.float32 ), \n",
    "                 \"SPEI\" : np.array( spei3mList, dtype=np.float32 ),\n",
    "                 \"Hist_SPEI\" : np.array( Hspei3mList, dtype=np.float32 ), }\n",
    "    cSP_3 = pd.DataFrame( index=cMMonPre.index, data=DataDict )\n",
    "    DictDF[bas] = cSP_3.copy()\n",
    "    # now do the stats\n",
    "    stats3SPIList = list()\n",
    "    stats3SPEIList = list()\n",
    "    indINList = list()\n",
    "    indENList = list()\n",
    "    for mI in range(1, 13, 1):\n",
    "        lDPre3Mon = PreM3MonDict[mI][1]\n",
    "        indINList.append( \"skew_%d\" % mI )\n",
    "        indINList.append( \"scale_%d\" % mI )\n",
    "        indINList.append( \"loc_%d\" % mI )\n",
    "        stats3SPIList.append( lDPre3Mon[\"skew\"] )\n",
    "        stats3SPIList.append( lDPre3Mon[\"scale\"] )\n",
    "        stats3SPIList.append( lDPre3Mon[\"location\"] )\n",
    "        lDDef3Mon = DefM3MonDict[mI][1]\n",
    "        indENList.append( \"shape_%d\" % mI )\n",
    "        indENList.append( \"scale_%d\" % mI )\n",
    "        indENList.append( \"loc_%d\" % mI )\n",
    "        stats3SPEIList.append( lDDef3Mon[\"k\"] )\n",
    "        stats3SPEIList.append( lDDef3Mon[\"scale\"] )\n",
    "        stats3SPEIList.append( lDDef3Mon[\"loc\"] )\n",
    "    # end for\n",
    "    # build our DataFrames\n",
    "    c3SPIStatsDF = pd.DataFrame( index=indINList, data={\"SPI Fit Stats\" : stats3SPIList,} )\n",
    "    c3SPEIStatsDF = pd.DataFrame( index=indENList, data={\"SPEI Fit Stats\" : stats3SPEIList,} )\n",
    "    StatsDictDF[bas] = [c3SPIStatsDF.copy(), c3SPEIStatsDF.copy()]\n",
    "    # do our plots\n",
    "    # SPEI\n",
    "    bT3Mo = cSP_3[[\"Year\", \"Month\", \"Hist_SPEI\"]].copy()\n",
    "    bT3Mo[\"AltYear\"] = bT3Mo[\"Year\"] - 38\n",
    "    pvbT3Mo = bT3Mo.pivot( index=\"AltYear\", columns=\"Month\", values=\"Hist_SPEI\")\n",
    "    NumYrs = len( pvbT3Mo )\n",
    "    allSPEI_1 = pvbT3Mo.to_numpy( dtype=np.float32 )\n",
    "    matLister1 = list()\n",
    "    for iI in range( NumYrs ):\n",
    "        rowLister = list()\n",
    "        for jJ in range(12):\n",
    "            cVal = allSPEI_1[iI, jJ]\n",
    "            if ( cVal >= 1.5 ) or ( cVal <= -1.5 ):\n",
    "                rowLister.append( \"%4.1f\" % cVal )\n",
    "            else:\n",
    "                rowLister.append( \"\" )\n",
    "            # end if\n",
    "        # end inner for\n",
    "        matLister1.append( rowLister )\n",
    "    # end outer for\n",
    "    AnnotMat_1 = np.array( matLister1 )\n",
    "    OutFilePDF = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"FBe-%s_SPEI_3mon-1993to2022.pdf\" % bas ) )\n",
    "    OutFileSVG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"FBe-%s_SPEI_3mon-1993to2022.svg\" % bas ) )\n",
    "    OutFilePNG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"FBe-%s_SPEI_3mon-1993to2022.png\" % bas ) )\n",
    "    Fig1 = plt.figure()\n",
    "    Fig1.set_size_inches(7.5, 10.5)\n",
    "    ax11 = Fig1.add_subplot(111)\n",
    "    ax11 = sns.heatmap( pvbT3Mo, vmin=pMin, vmax=pMax, cmap=SegCMap, center=0.0,\n",
    "                        annot=AnnotMat_1, fmt=\"s\", linecolor=\"gainsboro\", linewidths=0.0,\n",
    "                        annot_kws={'fontsize':9, 'color':'xkcd:black'},\n",
    "                        cbar_kws={'label': 'SPEI',}, ax=ax11 )\n",
    "    cbar = ax11.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=9)\n",
    "    ax11.set_title( \"%s Ensemble, 3-month SPEI (2031-2060 CN)\" % bas, fontsize=12 )\n",
    "    ax11.set_xlabel('Month', fontsize=10 )\n",
    "    ax11.set_ylabel('Year', fontsize=10)\n",
    "    ax11.tick_params(axis='both', which='major', labelsize=10)\n",
    "    Fig1.savefig( OutFileSVG, dpi=600 )\n",
    "    Fig1.savefig( OutFilePNG, dpi=600 )\n",
    "    Fig1.savefig( OutFilePDF, dpi=600 )\n",
    "    # clear the figures\n",
    "    plt.cla()\n",
    "    plt.close(Fig1)\n",
    "    # SPI\n",
    "    bT3Mo = cSP_3[[\"Year\", \"Month\", \"Hist_SPI\"]].copy()\n",
    "    bT3Mo[\"AltYear\"] = bT3Mo[\"Year\"] - 38\n",
    "    pvbT3Mo = bT3Mo.pivot( index=\"AltYear\", columns=\"Month\", values=\"Hist_SPI\")\n",
    "    NumYrs = len( pvbT3Mo )\n",
    "    allSPEI_1 = pvbT3Mo.to_numpy( dtype=np.float32 )\n",
    "    matLister1 = list()\n",
    "    for iI in range( NumYrs ):\n",
    "        rowLister = list()\n",
    "        for jJ in range(12):\n",
    "            cVal = allSPEI_1[iI, jJ]\n",
    "            if ( cVal >= 1.5 ) or ( cVal <= -1.5 ):\n",
    "                rowLister.append( \"%4.1f\" % cVal )\n",
    "            else:\n",
    "                rowLister.append( \"\" )\n",
    "            # end if\n",
    "        # end inner for\n",
    "        matLister1.append( rowLister )\n",
    "    # end outer for\n",
    "    AnnotMat_1 = np.array( matLister1 )\n",
    "    OutFilePDF = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"FBe-%s_SPI_3mon-1993to2022.pdf\" % bas ) )\n",
    "    OutFileSVG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"FBe-%s_SPI_3mon-1993to2022.svg\" % bas ) )\n",
    "    OutFilePNG = os.path.normpath( os.path.join( OUT_DIR, \"Plots\", \"FBe-%s_SPI_3mon-1993to2022.png\" % bas ) )\n",
    "    Fig1 = plt.figure()\n",
    "    Fig1.set_size_inches(7.5, 10.5)\n",
    "    ax11 = Fig1.add_subplot(111)\n",
    "    ax11 = sns.heatmap( pvbT3Mo, vmin=pMin, vmax=pMax, cmap=SegCMap, center=0.0,\n",
    "                        annot=AnnotMat_1, fmt=\"s\", linecolor=\"gainsboro\", linewidths=0.0,\n",
    "                        annot_kws={'fontsize':9, 'color':'xkcd:black'},\n",
    "                        cbar_kws={'label': 'SPI',}, ax=ax11 )\n",
    "    cbar = ax11.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=9)\n",
    "    ax11.set_title( \"%s Ensemble, 3-month SPI (2031-2060 CN)\" % bas, fontsize=12 )\n",
    "    ax11.set_xlabel('Month', fontsize=10 )\n",
    "    ax11.set_ylabel('Year', fontsize=10)\n",
    "    ax11.tick_params(axis='both', which='major', labelsize=10)\n",
    "    Fig1.savefig( OutFileSVG, dpi=600 )\n",
    "    Fig1.savefig( OutFilePNG, dpi=600 )\n",
    "    Fig1.savefig( OutFilePDF, dpi=600 )\n",
    "    # clear the figures\n",
    "    plt.cla()\n",
    "    plt.close(Fig1)\n",
    "# end basin for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3217344-c361-40a6-be2f-497e1e8b18a0",
   "metadata": {},
   "source": [
    "Collate the drought target information into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d2f328e-326f-4ec1-a77f-777ac116ae19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allKeys = sorted( DroughtTargsDict[BAS_KEYS[0]][3].keys() )\n",
    "len( allKeys )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ac1612c-df46-4f53-b850-9f023ee5e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAllKeys = [ \"ensemble\", 'M02H 2031-2060', 'M02L 2031-2060', 'M03H 2031-2060', 'M03L 2031-2060', 'M04H 2031-2060', 'M04L 2031-2060',\n",
    "             'M05H 2031-2060', 'M05L 2031-2060', 'M07H 2031-2060', 'M07L 2031-2060', 'M08H 2031-2060', 'M08L 2031-2060',\n",
    "             'M09H 2031-2060', 'M09L 2031-2060', 'M10H 2031-2060', 'M11H 2031-2060', 'M11L 2031-2060', 'M12H 2031-2060',\n",
    "             'M12L 2031-2060', ]\n",
    "len( mAllKeys )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45d10e43-c89b-46de-be5e-17ff03bd504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outIndexList = [ \"Jul-2022 3-month cum. deficit\", \"Jul-2022 SPEI cum. prob.\", \"5X cum. prob.\",]\n",
    "outIndexList.extend( mAllKeys )\n",
    "len( outIndexList )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c950395-35e2-454c-9d7a-1200c59adde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDict = dict()\n",
    "for bas in BAS_KEYS:\n",
    "    outLister = list()\n",
    "    outLister.append( DroughtTargsDict[bas][2] )\n",
    "    curCumProb = DroughtTargsDict[bas][1]\n",
    "    curCP5X = 5.0*curCumProb\n",
    "    outLister.append( curCumProb )\n",
    "    outLister.append( curCP5X )\n",
    "    for cAKey in mAllKeys:\n",
    "        outLister.append( DroughtTargsDict[bas][3][cAKey] )\n",
    "    # end for\n",
    "    DataDict[bas] = np.array( outLister, dtype=np.float32 )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83558adf-ed37-41ac-bd12-070be88e64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTSummDF = pd.DataFrame( index=outIndexList, data=DataDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c8a572a-99f9-46a3-abaa-1cdba31b47bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blanco</th>\n",
       "      <th>Cibolo</th>\n",
       "      <th>Frio</th>\n",
       "      <th>Guadalupe</th>\n",
       "      <th>Med-Cib</th>\n",
       "      <th>Medina</th>\n",
       "      <th>Nueces</th>\n",
       "      <th>Sab-Med</th>\n",
       "      <th>Sabinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jul-2022 3-month cum. deficit</th>\n",
       "      <td>-534.390198</td>\n",
       "      <td>-533.064636</td>\n",
       "      <td>-539.547729</td>\n",
       "      <td>-528.912842</td>\n",
       "      <td>-549.221680</td>\n",
       "      <td>-542.801514</td>\n",
       "      <td>-538.581970</td>\n",
       "      <td>-543.716736</td>\n",
       "      <td>-531.497803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul-2022 SPEI cum. prob.</th>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.042354</td>\n",
       "      <td>0.029823</td>\n",
       "      <td>0.027471</td>\n",
       "      <td>0.040599</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>0.046460</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.040542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5X cum. prob.</th>\n",
       "      <td>0.174845</td>\n",
       "      <td>0.211768</td>\n",
       "      <td>0.149113</td>\n",
       "      <td>0.137354</td>\n",
       "      <td>0.202995</td>\n",
       "      <td>0.135670</td>\n",
       "      <td>0.232299</td>\n",
       "      <td>0.152384</td>\n",
       "      <td>0.202711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.056472</td>\n",
       "      <td>0.058086</td>\n",
       "      <td>0.067510</td>\n",
       "      <td>0.062759</td>\n",
       "      <td>0.046603</td>\n",
       "      <td>0.054027</td>\n",
       "      <td>0.090919</td>\n",
       "      <td>0.066677</td>\n",
       "      <td>0.081483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02H 2031-2060</th>\n",
       "      <td>0.158851</td>\n",
       "      <td>0.163343</td>\n",
       "      <td>0.137907</td>\n",
       "      <td>0.157622</td>\n",
       "      <td>0.144155</td>\n",
       "      <td>0.143721</td>\n",
       "      <td>0.189095</td>\n",
       "      <td>0.166658</td>\n",
       "      <td>0.178190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02L 2031-2060</th>\n",
       "      <td>0.048966</td>\n",
       "      <td>0.051991</td>\n",
       "      <td>0.042243</td>\n",
       "      <td>0.039331</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>0.032195</td>\n",
       "      <td>0.069912</td>\n",
       "      <td>0.048467</td>\n",
       "      <td>0.057109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M03H 2031-2060</th>\n",
       "      <td>0.029702</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M03L 2031-2060</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M04H 2031-2060</th>\n",
       "      <td>0.087769</td>\n",
       "      <td>0.084264</td>\n",
       "      <td>0.107331</td>\n",
       "      <td>0.099353</td>\n",
       "      <td>0.065177</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>0.135856</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.123767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M04L 2031-2060</th>\n",
       "      <td>0.060246</td>\n",
       "      <td>0.062760</td>\n",
       "      <td>0.095130</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.049658</td>\n",
       "      <td>0.068429</td>\n",
       "      <td>0.128826</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>0.107862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M05H 2031-2060</th>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.061105</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.132765</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.068307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M05L 2031-2060</th>\n",
       "      <td>0.047991</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.078415</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.047928</td>\n",
       "      <td>0.057712</td>\n",
       "      <td>0.112115</td>\n",
       "      <td>0.069701</td>\n",
       "      <td>0.084451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M07H 2031-2060</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M07L 2031-2060</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.060610</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>0.038314</td>\n",
       "      <td>0.062717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M08H 2031-2060</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M08L 2031-2060</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M09H 2031-2060</th>\n",
       "      <td>0.108983</td>\n",
       "      <td>0.121459</td>\n",
       "      <td>0.145020</td>\n",
       "      <td>0.130314</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.126399</td>\n",
       "      <td>0.174173</td>\n",
       "      <td>0.141687</td>\n",
       "      <td>0.156375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M09L 2031-2060</th>\n",
       "      <td>0.053360</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>0.091928</td>\n",
       "      <td>0.082254</td>\n",
       "      <td>0.050443</td>\n",
       "      <td>0.071588</td>\n",
       "      <td>0.129807</td>\n",
       "      <td>0.081799</td>\n",
       "      <td>0.102592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M10H 2031-2060</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.018839</td>\n",
       "      <td>0.059658</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.043472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M11H 2031-2060</th>\n",
       "      <td>0.198687</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0.129849</td>\n",
       "      <td>0.181388</td>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.150924</td>\n",
       "      <td>0.150042</td>\n",
       "      <td>0.169037</td>\n",
       "      <td>0.178782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M11L 2031-2060</th>\n",
       "      <td>0.131040</td>\n",
       "      <td>0.138223</td>\n",
       "      <td>0.143598</td>\n",
       "      <td>0.142968</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.129812</td>\n",
       "      <td>0.164379</td>\n",
       "      <td>0.152554</td>\n",
       "      <td>0.170608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M12H 2031-2060</th>\n",
       "      <td>0.091951</td>\n",
       "      <td>0.088815</td>\n",
       "      <td>0.080156</td>\n",
       "      <td>0.091940</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.078532</td>\n",
       "      <td>0.094615</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.091542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M12L 2031-2060</th>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.105740</td>\n",
       "      <td>0.109634</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.082583</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.128534</td>\n",
       "      <td>0.121075</td>\n",
       "      <td>0.136355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( DTSummDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378df22a-f177-4627-aed5-36fa884ee297",
   "metadata": {},
   "source": [
    "Output to a summary spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff69144d-fd6e-4414-b043-1a1f87193320",
   "metadata": {},
   "outputs": [],
   "source": [
    "outXLSX = os.path.normpath( os.path.join( OUT_DIR, \"Basin_Ensembles_Summaries.xlsx\" ) )\n",
    "writer = pd.ExcelWriter( outXLSX )\n",
    "workbook  = writer.book\n",
    "format1 = workbook.add_format({'num_format': '#,##0.00'})\n",
    "cLabel = \"Drought Targets Summary\"\n",
    "DTSummDF.to_excel( writer, sheet_name=cLabel, )\n",
    "writer.sheets[cLabel].set_column( 0, 0, 20 )\n",
    "for column in DTSummDF:\n",
    "    column_width = max(DTSummDF[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "    col_idx = DTSummDF.columns.get_loc(column)\n",
    "    writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "# end for\n",
    "for bas in BAS_KEYS:\n",
    "    curDF = DictDF[bas]\n",
    "    cSPIStats = StatsDictDF[bas][0]\n",
    "    cSPEIStats = StatsDictDF[bas][1]\n",
    "    cLabel = \"%s_SPI_Info\" % bas\n",
    "    cSPIStats.to_excel( writer, sheet_name=cLabel, index_label=\"Parameter\" )\n",
    "    # adjust columns\n",
    "    writer.sheets[cLabel].set_column( 0, 0, 15 )\n",
    "    for column in cSPIStats:\n",
    "        column_width = max(cSPIStats[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "        col_idx = cSPIStats.columns.get_loc(column)\n",
    "        writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "    # end for\n",
    "    cLabel = \"%s_SPEI_Info\" % bas\n",
    "    cSPEIStats.to_excel( writer, sheet_name=cLabel, index_label=\"Parameter\" )\n",
    "    # adjust columns\n",
    "    writer.sheets[cLabel].set_column( 0, 0, 15 )\n",
    "    for column in cSPEIStats:\n",
    "        column_width = max(cSPEIStats[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "        col_idx = cSPEIStats.columns.get_loc(column)\n",
    "        writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "    # end for\n",
    "    cLabel = \"%s_Results\" % bas\n",
    "    curDF.to_excel( writer, sheet_name=cLabel, )\n",
    "    # adjust columns\n",
    "    writer.sheets[cLabel].set_column( 0, 0, 15 )\n",
    "    for column in curDF:\n",
    "        column_width = max(curDF[column].astype(str).map(len).max()+6, len(column)+6)\n",
    "        col_idx = curDF.columns.get_loc(column)\n",
    "        writer.sheets[cLabel].set_column(col_idx+1, col_idx+1, column_width, format1)\n",
    "    # end for\n",
    "# end basin for\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
